{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 918,
     "status": "ok",
     "timestamp": 1619194351776,
     "user": {
      "displayName": "Manish",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOzgftugjGlwJUwrdbX5XDqgTGARnH3uoArR2dPw=s64",
      "userId": "13981823828669335483"
     },
     "user_tz": -120
    },
    "id": "1R_iVP2P9TCu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "executionInfo": {
     "elapsed": 1011,
     "status": "ok",
     "timestamp": 1615900346044,
     "user": {
      "displayName": "Manish",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOzgftugjGlwJUwrdbX5XDqgTGARnH3uoArR2dPw=s64",
      "userId": "13981823828669335483"
     },
     "user_tz": -60
    },
    "id": "LaJgOwXhEpIs",
    "outputId": "374bb5da-de95-4b02-8bab-567d14007d2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1, 28, 28) float32\n",
      "(20000,) int64\n",
      "(2000, 1, 28, 28) float32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and read data from .npz file\n",
    "with np.load('prediction-challenge-01-data.npz') as fh:\n",
    "    data_x = fh['data_x']\n",
    "    data_y = fh['data_y']\n",
    "    test_x = fh['test_x']\n",
    "\n",
    "# TRAINING DATA: INPUT (x) AND OUTPUT (y)\n",
    "# 1. INDEX: IMAGE SERIAL NUMBER\n",
    "# 2. INDEX: COLOR CHANNEL\n",
    "# 3/4. INDEX: PIXEL VALUE\n",
    "print(data_x.shape, data_x.dtype)\n",
    "print(data_y.shape, data_y.dtype)\n",
    "\n",
    "# TEST DATA: INPUT (x) ONLY\n",
    "print(test_x.shape, test_x.dtype)\n",
    "\n",
    "# Data Visulisation\n",
    "plt.imshow(data_x[0, 0])\n",
    "plt.title(data_y[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgkVd8PaIGjt"
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vlCbIPO7FHRE"
   },
   "outputs": [],
   "source": [
    "# set training and validation set and test_set lengths\n",
    "data_len = data_x.shape[0]\n",
    "train_len, val_len = int(data_len * 0.8), int(data_len * 0.95)\n",
    "#random indices data \n",
    "indices = np.random.permutation(data_x.shape[0])\n",
    "train_idx, val_idx, test_idx = indices[:train_len], indices[train_len:val_len], indices[val_len:]\n",
    "# make train, val and test set\n",
    "train_x, train_y = data_x[:train_len], data_y[:train_len]\n",
    "val_x, val_y = data_x[train_len:val_len], data_y[train_len:val_len]\n",
    "intest_x, intest_y = data_x[val_len:], data_y[val_len:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eC7Q70UslB6W"
   },
   "source": [
    "# Mean\n",
    "\n",
    "Mean subtraction is the most common form of preprocessing. It involves subtracting the mean across every individual feature in the data\n",
    "\n",
    "#Normalisation\n",
    "in case of images, the relative scales of pixels are already approximately equal (and in range from 0 to 255), so it is not strictly necessary to perform this additional preprocessing step.\n",
    "\n",
    "https://cs231n.github.io/neural-networks-2/\n",
    "\n",
    "#Weight initialstion\n",
    "https://arxiv.org/abs/1502.01852"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2gUogDkk6a2"
   },
   "outputs": [],
   "source": [
    "#data_processing\n",
    "train_x = train_x / 255\n",
    "val_x = val_x / 255\n",
    "\n",
    "#weight initialisation if necessary\n",
    "#n = 28 * 28\n",
    "#w = np.random.randn(n) * np.sqrt(2.0/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnLNEwCjIaSq"
   },
   "source": [
    "# Data set up for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhATwR-LiEga"
   },
   "outputs": [],
   "source": [
    "# Data processing for pytorch\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_xt, train_yt, val_xt, val_yt, intest_xt, intest_yt = map(\n",
    "    torch.tensor, (train_x, train_y, val_x, val_y, intest_x, intest_y)\n",
    ")\n",
    "\n",
    "bs = 64  # batch size\n",
    "train_ds = TensorDataset(train_xt, train_yt)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(val_xt, val_yt)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZMgG7tPdnQz"
   },
   "source": [
    "# Define a Neural Network\n",
    "\n",
    "# with Linear layers : DO NOT GIVE GOOD RESULTS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3773,
     "status": "ok",
     "timestamp": 1619194350851,
     "user": {
      "displayName": "Manish",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOzgftugjGlwJUwrdbX5XDqgTGARnH3uoArR2dPw=s64",
      "userId": "13981823828669335483"
     },
     "user_tz": -120
    },
    "id": "V81yR_n0rlth"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1615900364260,
     "user": {
      "displayName": "Manish",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOzgftugjGlwJUwrdbX5XDqgTGARnH3uoArR2dPw=s64",
      "userId": "13981823828669335483"
     },
     "user_tz": -60
    },
    "id": "S78XlrTaplis",
    "outputId": "d4210dd2-379b-4730-e11f-3340df58f909"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (layer2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (layer3): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (layer4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Trial with linear layers : NOT GOOD RESULTS\n",
    "# Style 1\n",
    "class Net(nn.Module):\n",
    "   def __init__(self):\n",
    "     super(Net, self).__init__()\n",
    "     self.layer1 = nn.Linear(28*28, 512)\n",
    "     self.layer2 = nn.Linear(in_features=512, out_features=256)\n",
    "     self.layer3 = nn.Linear(in_features=256, out_features=64)\n",
    "     self.layer4 = nn.Linear(in_features=64, out_features=10)\n",
    "\n",
    "   def forward(self,x):\n",
    "     x = x.view(x.shape[0],-1)  #input X (64,1,28,28) reshape (64, 28*28) \n",
    "     out = self.layer1(x) #(64, 28*28) and (28*28, 512) gives (64, 512)\n",
    "     out1 = nn.functional.relu(out)\n",
    "\n",
    "     out2 = self.layer2(out1) #(64, 512) and (512, 512) gives (64, 512)\n",
    "     out2 = nn.functional.relu(out2) \n",
    "\n",
    "     out3 = self.layer3(out2) #(64, 512) and (512,10) gives (64, 10)\n",
    "     out3 = nn.functional.relu(out3) \n",
    "\n",
    "     out4 = self.layer4(out3) #(64, 512) and (512,10) gives (64, 10)\n",
    "     out4 = nn.functional.relu(out4) \n",
    "\n",
    "     return out1, out2, out3, out4\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zHRX9oMftQm"
   },
   "source": [
    "# with CONVOLUTIONAL layers : GIVES FAR BETTER RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1615902359158,
     "user": {
      "displayName": "Manish",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOzgftugjGlwJUwrdbX5XDqgTGARnH3uoArR2dPw=s64",
      "userId": "13981823828669335483"
     },
     "user_tz": -60
    },
    "id": "zLn529QIRSK9",
    "outputId": "82c2bf10-142a-4341-93da-b64e080e8759"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=1024, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Sequential way Conv : GOOD RESULTS\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "            #layer 1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, \n",
    "                      stride=1,padding=0 ),\n",
    "                      nn.ReLU(),\n",
    "                      nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                      )\n",
    "        #Layer 2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, \n",
    "                      kernel_size=5, stride=1,padding=0),\n",
    "                      nn.ReLU(),\n",
    "                      nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                      )\n",
    "\n",
    "        #layer fc1\n",
    "        self.fc1 = nn.Linear(in_features=4*4*64, out_features=64)\n",
    "        #layer fc2\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=10)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.layer1(x)\n",
    "        out2 = self.layer2(out1)\n",
    "        out2 = out2.view(out2.shape[0],-1)\n",
    "        out3 = self.fc1(out2)\n",
    "        out4 = self.fc2(out3)\n",
    "        return out1, out2, out3, out4\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7B2Hmtxiqjx"
   },
   "source": [
    "# Define a Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pykgCLpBdk1N"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr = learning_rate)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9JFO_s0kkJe"
   },
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELYw-BOaQT_8"
   },
   "source": [
    "model.eval() is a kind of switch for some specific layers/parts of the model that behave differently during training and inference (evaluating) time. For example, Dropouts Layers, BatchNorm Layers etc. You need to turn off them during model evaluation, and .eval() will do it for you. In addition, the common practice for evaluating/validation is using torch.no_grad() in pair with model.eval() to turn off gradients computation.\n",
    "\n",
    "model.eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode.\n",
    "torch.no_grad() impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you won’t be able to backprop (which you don’t want in an eval script).\n",
    "\n",
    "model.train() tells your model that you are training the model. So effectively layers like dropout, batchnorm etc. which behave different on the train and test procedures know what is going on and hence can behave accordingly. it just set the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 190867,
     "status": "ok",
     "timestamp": 1615902559155,
     "user": {
      "displayName": "Manish",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOzgftugjGlwJUwrdbX5XDqgTGARnH3uoArR2dPw=s64",
      "userId": "13981823828669335483"
     },
     "user_tz": -60
    },
    "id": "32vfQARh-W0H",
    "outputId": "7c52351c-812d-481a-ecb4-1f7b590dff10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.012144  [ 1600/16000]\n",
      "loss: 0.004359  [ 3200/16000]\n",
      "loss: 0.002488  [ 4800/16000]\n",
      "loss: 0.002059  [ 6400/16000]\n",
      "loss: 0.001774  [ 8000/16000]\n",
      "loss: 0.001546  [ 9600/16000]\n",
      "loss: 0.001480  [11200/16000]\n",
      "loss: 0.001084  [12800/16000]\n",
      "loss: 0.001010  [14400/16000]\n",
      "loss: 0.000926  [16000/16000]\n",
      "Training avg loss: 0.005774\n",
      "Validation Accuracy: 96.5%, validation avg loss: 0.002190\n",
      "model saved\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.000815  [ 1600/16000]\n",
      "loss: 0.000796  [ 3200/16000]\n",
      "loss: 0.000766  [ 4800/16000]\n",
      "loss: 0.000761  [ 6400/16000]\n",
      "loss: 0.000747  [ 8000/16000]\n",
      "loss: 0.000894  [ 9600/16000]\n",
      "loss: 0.000597  [11200/16000]\n",
      "loss: 0.000730  [12800/16000]\n",
      "loss: 0.000628  [14400/16000]\n",
      "loss: 0.000789  [16000/16000]\n",
      "Training avg loss: 0.001504\n",
      "Validation Accuracy: 97.1%, validation avg loss: 0.001890\n",
      "model saved\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.000543  [ 1600/16000]\n",
      "loss: 0.000528  [ 3200/16000]\n",
      "loss: 0.000513  [ 4800/16000]\n",
      "loss: 0.000452  [ 6400/16000]\n",
      "loss: 0.000525  [ 8000/16000]\n",
      "loss: 0.000591  [ 9600/16000]\n",
      "loss: 0.000353  [11200/16000]\n",
      "loss: 0.000489  [12800/16000]\n",
      "loss: 0.000591  [14400/16000]\n",
      "loss: 0.000307  [16000/16000]\n",
      "Training avg loss: 0.000978\n",
      "Validation Accuracy: 97.9%, validation avg loss: 0.001322\n",
      "model saved\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.000333  [ 1600/16000]\n",
      "loss: 0.000277  [ 3200/16000]\n",
      "loss: 0.000506  [ 4800/16000]\n",
      "loss: 0.000415  [ 6400/16000]\n",
      "loss: 0.000392  [ 8000/16000]\n",
      "loss: 0.000301  [ 9600/16000]\n",
      "loss: 0.000371  [11200/16000]\n",
      "loss: 0.000440  [12800/16000]\n",
      "loss: 0.000289  [14400/16000]\n",
      "loss: 0.000304  [16000/16000]\n",
      "Training avg loss: 0.000725\n",
      "Validation Accuracy: 98.5%, validation avg loss: 0.001083\n",
      "model saved\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.000288  [ 1600/16000]\n",
      "loss: 0.000247  [ 3200/16000]\n",
      "loss: 0.000254  [ 4800/16000]\n",
      "loss: 0.000213  [ 6400/16000]\n",
      "loss: 0.000336  [ 8000/16000]\n",
      "loss: 0.000382  [ 9600/16000]\n",
      "loss: 0.000296  [11200/16000]\n",
      "loss: 0.000316  [12800/16000]\n",
      "loss: 0.000245  [14400/16000]\n",
      "loss: 0.000219  [16000/16000]\n",
      "Training avg loss: 0.000559\n",
      "Validation Accuracy: 98.5%, validation avg loss: 0.000985\n",
      "model saved\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.000148  [ 1600/16000]\n",
      "loss: 0.000226  [ 3200/16000]\n",
      "loss: 0.000172  [ 4800/16000]\n",
      "loss: 0.000206  [ 6400/16000]\n",
      "loss: 0.000364  [ 8000/16000]\n",
      "loss: 0.000255  [ 9600/16000]\n",
      "loss: 0.000251  [11200/16000]\n",
      "loss: 0.000170  [12800/16000]\n",
      "loss: 0.000149  [14400/16000]\n",
      "loss: 0.000202  [16000/16000]\n",
      "Training avg loss: 0.000429\n",
      "Validation Accuracy: 98.0%, validation avg loss: 0.001439\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.000150  [ 1600/16000]\n",
      "loss: 0.000096  [ 3200/16000]\n",
      "loss: 0.000181  [ 4800/16000]\n",
      "loss: 0.000265  [ 6400/16000]\n",
      "loss: 0.000231  [ 8000/16000]\n",
      "loss: 0.000200  [ 9600/16000]\n",
      "loss: 0.000142  [11200/16000]\n",
      "loss: 0.000139  [12800/16000]\n",
      "loss: 0.000211  [14400/16000]\n",
      "loss: 0.000188  [16000/16000]\n",
      "Training avg loss: 0.000361\n",
      "Validation Accuracy: 98.0%, validation avg loss: 0.001419\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.000153  [ 1600/16000]\n",
      "loss: 0.000125  [ 3200/16000]\n",
      "loss: 0.000121  [ 4800/16000]\n",
      "loss: 0.000097  [ 6400/16000]\n",
      "loss: 0.000061  [ 8000/16000]\n",
      "loss: 0.000154  [ 9600/16000]\n",
      "loss: 0.000190  [11200/16000]\n",
      "loss: 0.000259  [12800/16000]\n",
      "loss: 0.000252  [14400/16000]\n",
      "loss: 0.000233  [16000/16000]\n",
      "Training avg loss: 0.000329\n",
      "Validation Accuracy: 98.8%, validation avg loss: 0.000981\n",
      "model saved\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.000142  [ 1600/16000]\n",
      "loss: 0.000082  [ 3200/16000]\n",
      "loss: 0.000055  [ 4800/16000]\n",
      "loss: 0.000087  [ 6400/16000]\n",
      "loss: 0.000116  [ 8000/16000]\n",
      "loss: 0.000106  [ 9600/16000]\n",
      "loss: 0.000087  [11200/16000]\n",
      "loss: 0.000120  [12800/16000]\n",
      "loss: 0.000125  [14400/16000]\n",
      "loss: 0.000141  [16000/16000]\n",
      "Training avg loss: 0.000212\n",
      "Validation Accuracy: 98.2%, validation avg loss: 0.001291\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.000072  [ 1600/16000]\n",
      "loss: 0.000126  [ 3200/16000]\n",
      "loss: 0.000130  [ 4800/16000]\n",
      "loss: 0.000127  [ 6400/16000]\n",
      "loss: 0.000066  [ 8000/16000]\n",
      "loss: 0.000063  [ 9600/16000]\n",
      "loss: 0.000063  [11200/16000]\n",
      "loss: 0.000106  [12800/16000]\n",
      "loss: 0.000106  [14400/16000]\n",
      "loss: 0.000042  [16000/16000]\n",
      "Training avg loss: 0.000180\n",
      "Validation Accuracy: 98.6%, validation avg loss: 0.001213\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.000070  [ 1600/16000]\n",
      "loss: 0.000066  [ 3200/16000]\n",
      "loss: 0.000076  [ 4800/16000]\n",
      "loss: 0.000080  [ 6400/16000]\n",
      "loss: 0.000046  [ 8000/16000]\n",
      "loss: 0.000052  [ 9600/16000]\n",
      "loss: 0.000096  [11200/16000]\n",
      "loss: 0.000154  [12800/16000]\n",
      "loss: 0.000094  [14400/16000]\n",
      "loss: 0.000209  [16000/16000]\n",
      "Training avg loss: 0.000188\n",
      "Validation Accuracy: 98.5%, validation avg loss: 0.001278\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.000095  [ 1600/16000]\n",
      "loss: 0.000063  [ 3200/16000]\n",
      "loss: 0.000073  [ 4800/16000]\n",
      "loss: 0.000130  [ 6400/16000]\n",
      "loss: 0.000082  [ 8000/16000]\n",
      "loss: 0.000059  [ 9600/16000]\n",
      "loss: 0.000035  [11200/16000]\n",
      "loss: 0.000043  [12800/16000]\n",
      "loss: 0.000040  [14400/16000]\n",
      "loss: 0.000073  [16000/16000]\n",
      "Training avg loss: 0.000139\n",
      "Validation Accuracy: 98.6%, validation avg loss: 0.001289\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.000053  [ 1600/16000]\n",
      "loss: 0.000043  [ 3200/16000]\n",
      "loss: 0.000039  [ 4800/16000]\n",
      "loss: 0.000081  [ 6400/16000]\n",
      "loss: 0.000051  [ 8000/16000]\n",
      "loss: 0.000055  [ 9600/16000]\n",
      "loss: 0.000061  [11200/16000]\n",
      "loss: 0.000066  [12800/16000]\n",
      "loss: 0.000055  [14400/16000]\n",
      "loss: 0.000033  [16000/16000]\n",
      "Training avg loss: 0.000107\n",
      "Validation Accuracy: 99.0%, validation avg loss: 0.001009\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.000086  [ 1600/16000]\n",
      "loss: 0.000055  [ 3200/16000]\n",
      "loss: 0.000034  [ 4800/16000]\n",
      "loss: 0.000050  [ 6400/16000]\n",
      "loss: 0.000051  [ 8000/16000]\n",
      "loss: 0.000021  [ 9600/16000]\n",
      "loss: 0.000016  [11200/16000]\n",
      "loss: 0.000014  [12800/16000]\n",
      "loss: 0.000019  [14400/16000]\n",
      "loss: 0.000025  [16000/16000]\n",
      "Training avg loss: 0.000074\n",
      "Validation Accuracy: 99.0%, validation avg loss: 0.001070\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.000026  [ 1600/16000]\n",
      "loss: 0.000030  [ 3200/16000]\n",
      "loss: 0.000012  [ 4800/16000]\n",
      "loss: 0.000005  [ 6400/16000]\n",
      "loss: 0.000003  [ 8000/16000]\n",
      "loss: 0.000006  [ 9600/16000]\n",
      "loss: 0.000009  [11200/16000]\n",
      "loss: 0.000013  [12800/16000]\n",
      "loss: 0.000035  [14400/16000]\n",
      "loss: 0.000030  [16000/16000]\n",
      "Training avg loss: 0.000034\n",
      "Validation Accuracy: 98.7%, validation avg loss: 0.001269\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.000111  [ 1600/16000]\n",
      "loss: 0.000128  [ 3200/16000]\n",
      "loss: 0.000036  [ 4800/16000]\n",
      "loss: 0.000072  [ 6400/16000]\n",
      "loss: 0.000095  [ 8000/16000]\n",
      "loss: 0.000207  [ 9600/16000]\n",
      "loss: 0.000148  [11200/16000]\n",
      "loss: 0.000151  [12800/16000]\n",
      "loss: 0.000119  [14400/16000]\n",
      "loss: 0.000098  [16000/16000]\n",
      "Training avg loss: 0.000233\n",
      "Validation Accuracy: 98.0%, validation avg loss: 0.001801\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.000104  [ 1600/16000]\n",
      "loss: 0.000094  [ 3200/16000]\n",
      "loss: 0.000156  [ 4800/16000]\n",
      "loss: 0.000044  [ 6400/16000]\n",
      "loss: 0.000100  [ 8000/16000]\n",
      "loss: 0.000061  [ 9600/16000]\n",
      "loss: 0.000036  [11200/16000]\n",
      "loss: 0.000050  [12800/16000]\n",
      "loss: 0.000014  [14400/16000]\n",
      "loss: 0.000014  [16000/16000]\n",
      "Training avg loss: 0.000135\n",
      "Validation Accuracy: 98.7%, validation avg loss: 0.001165\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.000020  [ 1600/16000]\n",
      "loss: 0.000009  [ 3200/16000]\n",
      "loss: 0.000007  [ 4800/16000]\n",
      "loss: 0.000010  [ 6400/16000]\n",
      "loss: 0.000009  [ 8000/16000]\n",
      "loss: 0.000008  [ 9600/16000]\n",
      "loss: 0.000011  [11200/16000]\n",
      "loss: 0.000022  [12800/16000]\n",
      "loss: 0.000025  [14400/16000]\n",
      "loss: 0.000033  [16000/16000]\n",
      "Training avg loss: 0.000031\n",
      "Validation Accuracy: 98.6%, validation avg loss: 0.001429\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.000019  [ 1600/16000]\n",
      "loss: 0.000010  [ 3200/16000]\n",
      "loss: 0.000005  [ 4800/16000]\n",
      "loss: 0.000020  [ 6400/16000]\n",
      "loss: 0.000032  [ 8000/16000]\n",
      "loss: 0.000009  [ 9600/16000]\n",
      "loss: 0.000006  [11200/16000]\n",
      "loss: 0.000006  [12800/16000]\n",
      "loss: 0.000005  [14400/16000]\n",
      "loss: 0.000003  [16000/16000]\n",
      "Training avg loss: 0.000023\n",
      "Validation Accuracy: 98.8%, validation avg loss: 0.001188\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.000001  [ 1600/16000]\n",
      "loss: 0.000001  [ 3200/16000]\n",
      "loss: 0.000001  [ 4800/16000]\n",
      "loss: 0.000001  [ 6400/16000]\n",
      "loss: 0.000002  [ 8000/16000]\n",
      "loss: 0.000001  [ 9600/16000]\n",
      "loss: 0.000001  [11200/16000]\n",
      "loss: 0.000001  [12800/16000]\n",
      "loss: 0.000009  [14400/16000]\n",
      "loss: 0.000009  [16000/16000]\n",
      "Training avg loss: 0.000005\n",
      "Validation Accuracy: 98.8%, validation avg loss: 0.001141\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "training_size = len(train_dl.dataset)\n",
    "loss_epoch_trn_list, loss_epoch_val_list = [], [] # loss storage lists\n",
    "\n",
    "for epoch in range(20):\n",
    "  running_trn_loss, running_batch_trn_loss = 0.0 , 0.0\n",
    "  print(f\"\\nEpoch {epoch+1}\\n-------------------------------\")\n",
    "  \n",
    "  # TRAINING\n",
    "  net.train()\n",
    "\n",
    "  for batch_num, (input, label) in enumerate(train_dl):\n",
    "    #input, label = input.to(device), label.to(device)\n",
    "\n",
    "    # prediction\n",
    "    pred = net(input) \n",
    "    loss = criterion(pred[3], label) #evalute loss\n",
    "    \n",
    "    # backpropogation \n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad() # zeroes the parameter gradients\n",
    "    \n",
    "    # statistics\n",
    "    running_trn_loss += loss.item()\n",
    "    running_batch_trn_loss += loss.item() \n",
    "         \n",
    "    if batch_num % 25 == 24:\n",
    "      current_index = (batch_num+1) * bs\n",
    "      print(f\"loss: {running_batch_trn_loss/(50 * bs) :>7f}  [{current_index:>5d}/{training_size:>5d}]\")\n",
    "      running_batch_trn_loss = 0\n",
    "  \n",
    "  # cummulative training loss after each epoch\n",
    "  epoch_mean_trn_loss = running_trn_loss / training_size\n",
    "  loss_epoch_trn_list.append(epoch_mean_trn_loss)\n",
    "  print(f\"Training avg loss: {loss_epoch_trn_list[-1]:>7f}\")\n",
    "  \n",
    "  \n",
    "  # VALIDATION\n",
    "  net.eval()\n",
    "  \n",
    "  validation_size = len(valid_dl.dataset)\n",
    "  running_val_loss, correct_prediction = 0, 0\n",
    "  with torch.no_grad():\n",
    "    for X, y in valid_dl:\n",
    "      val_pred = net(X)\n",
    "      val_loss = criterion(val_pred[3], y)\n",
    "      running_val_loss += val_loss.item()\n",
    "      correct_prediction += (y == torch.argmax(val_pred[3],dim=1)).float().sum().item()\n",
    "  \n",
    "  val_accuracy = correct_prediction / validation_size * 100\n",
    "  epoch_mean_val_loss = running_val_loss / validation_size\n",
    "  loss_epoch_val_list.append(epoch_mean_val_loss) # append to list\n",
    "  print(f\"Validation Accuracy: {(val_accuracy):>0.1f}%, validation avg loss: {loss_epoch_val_list[-1]:>8f}\")\n",
    "\n",
    "  #saving model for minimum validation loss\n",
    "  if loss_epoch_val_list[-1] <= min(loss_epoch_val_list):\n",
    "    print(\"model saved\\n\")\n",
    "    torch.save(net, './best_mnist_net.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXR8-1IWgXcM"
   },
   "source": [
    "# validation vs test error : Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1615902611069,
     "user": {
      "displayName": "Manish",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOzgftugjGlwJUwrdbX5XDqgTGARnH3uoArR2dPw=s64",
      "userId": "13981823828669335483"
     },
     "user_tz": -60
    },
    "id": "N03vRbiinNcW",
    "outputId": "5964322b-2998-4830-b5e7-be91162e73b9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "fig,ax = plt.subplots(figsize=(10, 6))\n",
    "x_points = np.arange(1, epoch+2, 1 )\n",
    "x_points_ = np.arange(1, epoch+3, 4 )\n",
    "ax.set_xticks(x_points_)\n",
    "ax.set_xlabel('epoch number',fontsize=15, labelpad =3)\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax.tick_params(which='major', width=0.7,length=17,direction=\"out\" , labelleft=True )\n",
    "ax.tick_params(which='minor', width=0.7, length=10, color='r', direction=\"out\")\n",
    "ax.set_ylabel('Loss',fontsize=15, labelpad=15)\n",
    "ax.plot(x_points, loss_epoch_trn_list , color = 'black', marker='o', markersize=5 , linestyle='dashed', dashes=(15, 10),linewidth=0.2) \n",
    "ax.plot(x_points, loss_epoch_val_list , color = 'black', marker='v', markersize=5 , linestyle='solid', linewidth=0.2) \n",
    "ax.legend(['Training loss','Validation loss' ], loc='best', fontsize=15, frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5FOHXOxu3NL"
   },
   "source": [
    "# Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZC89iDdXaRSF"
   },
   "outputs": [],
   "source": [
    "#load model and continue training\n",
    "PATH = './best_mnist_net.pth'\n",
    "our_saved_model = torch.load(PATH)\n",
    "#for training\n",
    "#new_model.train()\n",
    "#Todo make train function and run training\n",
    "#for validation\n",
    "#new_model.eval()\n",
    "#Todo make validate function and run validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KB0HgCPUg0md"
   },
   "source": [
    "# Generalisation in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pB0kM5SeTjc3"
   },
   "outputs": [],
   "source": [
    "intest_x = intest_x / 255\n",
    "intest_xt = torch.tensor(intest_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 799,
     "status": "ok",
     "timestamp": 1615903221068,
     "user": {
      "displayName": "Manish",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOzgftugjGlwJUwrdbX5XDqgTGARnH3uoArR2dPw=s64",
      "userId": "13981823828669335483"
     },
     "user_tz": -60
    },
    "id": "mt_ouJ7cCGT_",
    "outputId": "43c63c3b-bbe2-475b-a002-678e2cc03596"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset Accuracy: 98.6%\n"
     ]
    }
   ],
   "source": [
    "test_size = intest_xt.shape[0]\n",
    "our_saved_model.eval()\n",
    "with torch.no_grad():\n",
    "  test_predi = our_saved_model(intest_xt)\n",
    "  correct_pred = intest_yt.eq(torch.argmax(test_predi[3],dim=1))\n",
    "  correct_pred = correct_pred.float().sum().item()\n",
    "  nd_test_prediction = torch.argmax(test_predi[3],dim=1).numpy()\n",
    "  test_accuracy = correct_pred / test_size * 100\n",
    "  print(f\"Testset Accuracy: {(test_accuracy):>0.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCU0DhjduvO8"
   },
   "source": [
    "#access parameters of a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C4I0tgP-s1iw"
   },
   "outputs": [],
   "source": [
    "#parameters of a layer\n",
    "weights_4 = net.layer4.weight\n",
    "bias_4 = net.layer4.bias\n",
    "print(weights_4.shape)\n",
    "print(bias_4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nkj4QpbnRSz"
   },
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 558,
     "status": "ok",
     "timestamp": 1615841336848,
     "user": {
      "displayName": "Manish",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOzgftugjGlwJUwrdbX5XDqgTGARnH3uoArR2dPw=s64",
      "userId": "13981823828669335483"
     },
     "user_tz": -60
    },
    "id": "KqTm-HUC72Pu",
    "outputId": "1e47cf16-04c1-4cf1-d57f-08ce4bd3a906"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "layer1.weight \t torch.Size([512, 784])\n",
      "layer1.bias \t torch.Size([512])\n",
      "layer2.weight \t torch.Size([256, 512])\n",
      "layer2.bias \t torch.Size([256])\n",
      "layer3.weight \t torch.Size([64, 256])\n",
      "layer3.bias \t torch.Size([64])\n",
      "layer4.weight \t torch.Size([10, 64])\n",
      "layer4.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in net.state_dict():\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "#print(\"Optimizer's state_dict:\")\n",
    "#for var_name in optimizer.state_dict():\n",
    "#    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHNsGF36zBxE"
   },
   "source": [
    "# Visualize feature map\n",
    "\n",
    "https://discuss.pytorch.org/t/visualize-feature-map/29597\n",
    "\n",
    "detach function\n",
    "\n",
    "http://www.bnikolic.co.uk/blog/pytorch-detach.html\n",
    "\n",
    "1. detach() detaches the output from the computationnal graph. So no gradient will be backproped along this variable.\n",
    "torch.no_grad says that no operation should build the graph.\n",
    "\n",
    "2. The difference is that one refers to only a given variable on which it’s called. The other affects all operations taking place within the with statement.\n",
    "\n",
    "3. torch.no_grad can be used in eval phase in general.\n",
    " detach() on the other hand should not be used if you’re doing classic cnn like architectures. It is usually used for more tricky operations. detach() is useful when you want to compute something that you can’t / don’t want to differentiate. Like for example if you’re computing some indices from the output of the network and then want to use that to index a tensor. The indexing operation is not differentiable wrt the indices. So you should detach() the indices before providing them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMjOX4kt3xau"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1615842196388,
     "user": {
      "displayName": "Manish",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOzgftugjGlwJUwrdbX5XDqgTGARnH3uoArR2dPw=s64",
      "userId": "13981823828669335483"
     },
     "user_tz": -60
    },
    "id": "keomAaGzrsOC",
    "outputId": "3f35b225-94d8-4271-9ee0-46c13db03224"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 64])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Visualize feature maps\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "model.conv1.register_forward_hook(get_activation('conv1'))\n",
    "data, _ = dataset[0]\n",
    "data.unsqueeze_(0)\n",
    "output = model(data)\n",
    "\n",
    "act = activation['conv1'].squeeze()\n",
    "fig, axarr = plt.subplots(act.size(0))\n",
    "for idx in range(act.size(0)):\n",
    "    axarr[idx].imshow(act[idx])\n",
    "\n",
    "\n",
    "for name, layer in model_1.named_modules():\n",
    "    layer.register_forward_hook(get_activation(name))\n",
    "\n",
    "x = torch.randn(1, 10)\n",
    "output = model(x)\n",
    "for key in activation:\n",
    "    print(activation[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SWQxyBnXzbHo"
   },
   "outputs": [],
   "source": [
    "# Visualize conv filter\n",
    "kernels = model.conv1.weight.detach()\n",
    "fig, axarr = plt.subplots(kernels.size(0))\n",
    "for idx in range(kernels.size(0)):\n",
    "    axarr[idx].imshow(kernels[idx].squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iecdE9QOw1fj"
   },
   "source": [
    "# paramters (weights and bias) of each layer IF sequential saved\n",
    "for example:\n",
    "            \n",
    "            self.linear_relu_stack = \n",
    "            nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WAx3FsV3uENM"
   },
   "outputs": [],
   "source": [
    "layer_1 = net.linear_relu_stack[0]\n",
    "print(layer_1.bias.shape)\n",
    "print(layer_1.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpUI1eJCvdOM"
   },
   "outputs": [],
   "source": [
    "for name, layer in model_1.named_modules():\n",
    "    layer.register_forward_hook(get_activation(name))\n",
    "\n",
    "x = torch.randn(1, 10)\n",
    "output = model(x)\n",
    "for key in activation:\n",
    "    print(activation[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5ZH1BwdkfQA"
   },
   "source": [
    "# Clean Code:\n",
    "Redefining network in Functional way: An example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COhUUm2kbmTZ"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "  '''\n",
    "  Training phase of the network\n",
    "\n",
    "  i/p: \n",
    "  dataloader: training data loader\n",
    "  model: nueral network model object\n",
    "  loss_fn: error function criteria\n",
    "  optimizer: optimizer method\n",
    "\n",
    "  returns:\n",
    "  running_trn_loss: Training avg training loss of each epoch\n",
    "  '''\n",
    "  for batch_num, data in enumerate(train_dl):\n",
    "    #input, label = input.to(device), label.to(device)\n",
    "    input, label = data # size [64,1,128,128], [64]\n",
    "    \n",
    "    # prediction\n",
    "    pred = model(input) \n",
    "    loss = criterion(pred[3], label) #evalute loss, pred[] \n",
    "       \n",
    "    # backpropogation \n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad() # zeroes the parameter gradients\n",
    "    \n",
    "    # statistics\n",
    "    running_trn_loss += loss.item()\n",
    "    running_batch_trn_loss += loss.item() \n",
    "         \n",
    "    if batch_num % 25 == 24:\n",
    "      current_index = (batch_num+1) * bs\n",
    "      print(f\"loss: {running_batch_trn_loss/(50 * bs) :>7f}  [{current_index:>5d}/{training_size:>5d}]\")\n",
    "      running_batch_trn_loss = 0\n",
    "  epoch_mean_trn_loss = running_trn_loss / training_size\n",
    "  return epoch_mean_trn_loss\n",
    "  \n",
    "loss_epoch_trn_list.append(epoch_mean_trn_loss)\n",
    "print(f\"Training avg loss: {loss_epoch_trn_list[-1]:>7f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54LrD30aj_Bq"
   },
   "outputs": [],
   "source": [
    "def validation(dataloader, model, loss_fn):\n",
    "  '''\n",
    "  Validation phase of the network\n",
    "\n",
    "  i/p: \n",
    "  dataloader: validation data loader\n",
    "  model: nueral network model object\n",
    "  loss_fn: error function criteria\n",
    "\n",
    "  returns:\n",
    "  running_trn_loss: Cummulative validation loss of each epoch\n",
    "  '''\n",
    "\n",
    "  validation_size = len(dataloader.dataset)\n",
    "  running_val_loss, correct_prediction = 0, 0\n",
    "  \n",
    "  net.eval()\n",
    "  with torch.no_grad():\n",
    "    for X, y in dataloader:\n",
    "      val_pred = model(X)\n",
    "      val_loss = loss_fn(val_pred[3], y)\n",
    "      running_val_loss += val_loss.item()\n",
    "      correct_prediction += (y == torch.argmax(val_pred[3],dim=1)).float().sum().item()\n",
    "  \n",
    "  val_accuracy = correct_prediction / validation_size * 100\n",
    "  epoch_mean_val_loss = running_val_loss / validation_size\n",
    "  loss_epoch_val_list.append(epoch_mean_val_loss) # append to list\n",
    "  print(f\"Validation Accuracy: {(val_accuracy):>0.1f}%, validation avg loss: {loss_epoch_val_list[-1]:>8f} \\n\")\n",
    "\n",
    "  #saving model for minimum validation loss\n",
    "  if loss_epoch_val_list[-1] <= min(loss_epoch_val_list):\n",
    "    print(\"model saved at\", epoch)\n",
    "    torch.save(net, './best_mnist_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ZH4wxb_tPEU"
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "model_1 = torch.load('net.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0VEA3JQGkzM7"
   },
   "source": [
    "# Cleaner code : pytorch website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFsDAdMjJzQp"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        \n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            \n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20939,
     "status": "ok",
     "timestamp": 1615813506580,
     "user": {
      "displayName": "Manish",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOzgftugjGlwJUwrdbX5XDqgTGARnH3uoArR2dPw=s64",
      "userId": "13981823828669335483"
     },
     "user_tz": -60
    },
    "id": "karNTivyxWuV",
    "outputId": "d34815d1-c9bb-4a05-a2ad-a1a4eafcc66a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 18.486181  [    0/16000]\n",
      "loss: 18.826414  [ 6400/16000]\n",
      "loss: 19.768499  [12800/16000]\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.399434 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 21.409977  [    0/16000]\n",
      "loss: 20.177744  [ 6400/16000]\n",
      "loss: 20.319199  [12800/16000]\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.399434 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 20.475042  [    0/16000]\n",
      "loss: 18.319780  [ 6400/16000]\n",
      "loss: 20.737833  [12800/16000]\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.399434 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 19.328180  [    0/16000]\n",
      "loss: 18.103186  [ 6400/16000]\n",
      "loss: 19.199057  [12800/16000]\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.399434 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 21.236141  [    0/16000]\n",
      "loss: 20.639696  [ 6400/16000]\n",
      "loss: 19.110626  [12800/16000]\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.399434 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Dataset is 160000 while Dataset.dataloader is and iterable of 16000/batch_size\n",
    "train_dl.dataset\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dl, net, criterion, optimizer)\n",
    "    test(valid_dl, net, criterion )\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V8jp-dQXlTLB"
   },
   "outputs": [],
   "source": [
    "#code for assignment submission\n",
    "import numpy as np\n",
    "\n",
    "prediction = nd_test_prediction # THAT'S YOUR JOB\n",
    "\n",
    "# MAKE SURE THAT YOU HAVE THE RIGHT FORMAT\n",
    "assert prediction.ndim == 1\n",
    "assert prediction.shape[0] == 1000\n",
    "\n",
    "# AND SAVE EXACTLY AS SHOWN BELOW\n",
    "np.save('./prediction.npy', prediction)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMU+7VNM0jdw/PK/NxFvLff",
   "collapsed_sections": [],
   "name": "deep_L1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
